## Step 1: Set Up AWS OpenSearch Domain

1. **Log in** to the [AWS Management Console](https://aws.amazon.com/console/).
2. **Navigate** to **Amazon OpenSearch Service** under **Analytics**.
3. **Create a new domain** or select an existing domain to use for this pipeline.
4. Ensure that your domain has sufficient permissions and resources to handle log ingestion, processing, and anomaly detection.

## Step 2: Create IAM Roles for Pipeline Access

1. **Create an IAM role** with permissions to access your OpenSearch domain and any required S3 buckets.
2. Ensure the role has a trust relationship with `osis-pipelines.amazonaws.com`.
3. **Attach policies** that allow the role to:
   - Access and write to the OpenSearch domain.
   - Write to an S3 bucket for Dead Letter Queue (DLQ) if needed.

## Step 3: Define Your Pipeline Configuration

You will need to create a YAML configuration file that defines the structure of your OpenSearch pipeline.

### Example Configuration

Below is an example pipeline configuration:

```yaml
version: "2"
log-pipeline:
  source:
    http:
      path: "/syslog-pipeline/logs"
  processor:
    - grok:
        match:
          log: [ "%{SYSLOGBASE}" ]
  sink:
    - opensearch:
        hosts: [ "https://<your-opensearch-endpoint>" ]
        aws:
          sts_role_arn: "arn:aws:iam::<your-account-id>:role/<your-iam-role>"
          region: "<your-region>"
          serverless: false
        index: "<your-index-name>"
        dlq:
          s3:
            bucket: "<your-s3-bucket>"
            region: "<your-region>"
            sts_role_arn: "arn:aws:iam::<your-account-id>:role/<your-iam-role>"
```

### Configuration Breakdown

- **apache-log-pipeline-with-metrics**: Ingests Apache logs via HTTP, parses them using Grok, and stores them in an OpenSearch index.
- **log-to-metrics-pipeline**: Aggregates logs into metrics, storing them in a different OpenSearch index.
- **log-to-metrics-anomaly-detector-pipeline**: Runs anomaly detection on the metrics and stores the results in another OpenSearch index.

## Step 4: Deploy the Pipeline

1. **Log in** to the [OpenSearch Ingestion Service](https://opensearch.aws.amazon.com/).
2. **Create a new pipeline** and upload your YAML configuration file.
3. **Deploy** the pipeline by following the prompts.

![image](https://github.com/user-attachments/assets/5b89da60-85a4-4cc9-938c-079defe45d43)

## Step 5: Test the Pipeline

1. **Send test logs** to your pipelineâ€™s HTTP endpoint.
2. **Verify** that logs are ingested, processed, and anomalies are detected by checking your OpenSearch Dashboards.

![image](https://github.com/user-attachments/assets/1772e0f8-f424-4705-96c7-bd6495178519)

## Step 6: Monitor and Maintain

1. Regularly **monitor the pipeline** for performance and anomalies.
2. **Adjust configurations** as needed to optimize performance or handle new log formats.

## Conclusion

By following this guide, you have successfully set up an AWS OpenSearch pipeline for processing Apache logs, converting them into metrics, and detecting anomalies.
